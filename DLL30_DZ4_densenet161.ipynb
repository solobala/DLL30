{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10705,"sourceType":"datasetVersion","datasetId":7160}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marinabalakina/dll30-dz4-4?scriptVersionId=155050799\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# ** Домашнее** задание по теме «Архитектуры свёрточных сетей»\n\nЦель задания: изучить работу с готовыми моделями из torchvision.\n\nКонтекст\n\nВам необходимо подобрать базовую модель для работы по вашей задаче. Вы пробуете обучать различные модели на “ваших” данных. По результатам отберёте лучшую для дальнейшего обучения.\n\nЗадание\n\nВам необходимо провести эксперименты по начальному обучению различных моделей и сравнить результаты.\n\n1.Возьмите датасет EMNIST из torchvision\n\n2. Обучите на нём модели: ResNet 18, VGG 16, Inception v3, DenseNet 161 (с нуля по 10 эпох)\n\n3. Сведите результаты обучения моделей (графики лоса) в таблицу и сравните их.\n\n\nЗадание со звездочкой*\n\n* Выполните то же задание, используя датасет hymenoptera_data\n\nИнструкция к выполнению задания\n\n* Загрузите датасет, посмотрите примеры картинок в нём и проверьте наличествующие классы и их дисбаланс.\n\n* Создайте модель текущего типа, используя интерфейс torchvision для нужного количества классов.\n\n* Обучите модель с нуля 10 эпох. Фиксируйте значение функции потерь в список для последующего отображения.\n\nПовторите пункты 2 и 3 для всех указанных вариантов моделей.\n\nФормат сдачи работы\n\nПрикрепите ссылку на готовое решение в личном кабинете. Работу можно отправлять в виде ссылки на python-ноутбук из GitHub, Google Colaboratory или аналогичных платформ. Не забудьте открыть доступ на просмотр и комментирование.\n\nКритерии оценивания\nПо итогу выполнения задания вы получите зачёт.\n\nЗадание считается выполненным, если:\n\nвы обучили каждую модель до некоторого улучшения качества\n\nсоставлена таблица обучения для сравнения\n\nЗадание будет отправлено на доработку, если:\n\nиспользованы не все типы моделей\n\nне составлена сводная таблица с результатами","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Импорт библиотек и пользовательские функции","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:37:48.304959Z","iopub.execute_input":"2023-12-14T19:37:48.30561Z","iopub.status.idle":"2023-12-14T19:37:48.65378Z","shell.execute_reply.started":"2023-12-14T19:37:48.305572Z","shell.execute_reply":"2023-12-14T19:37:48.652918Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision as tv # consists of popular datasets, model architectures, and common image transformations for computer vision - для работы с предобученными нейросетями\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:37:51.042352Z","iopub.execute_input":"2023-12-14T19:37:51.043216Z","iopub.status.idle":"2023-12-14T19:37:52.670825Z","shell.execute_reply.started":"2023-12-14T19:37:51.043181Z","shell.execute_reply":"2023-12-14T19:37:52.670048Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:37:54.298309Z","iopub.execute_input":"2023-12-14T19:37:54.298833Z","iopub.status.idle":"2023-12-14T19:37:54.33803Z","shell.execute_reply.started":"2023-12-14T19:37:54.298801Z","shell.execute_reply":"2023-12-14T19:37:54.337115Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"def evaluate_accuracy(data_iter, net):\n    acc_sum, n = 0, 0\n    net.eval()\n    for X, y in data_iter:\n        X, y = X.to(device), y.to(device)\n        acc_sum += (net(X).argmax(axis=1) == y).sum()\n        n += y.shape[0]\n    return acc_sum.item() / n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:37:57.025363Z","iopub.execute_input":"2023-12-14T19:37:57.025769Z","iopub.status.idle":"2023-12-14T19:37:57.031992Z","shell.execute_reply.started":"2023-12-14T19:37:57.025735Z","shell.execute_reply":"2023-12-14T19:37:57.03102Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train(net, train_iter, test_iter, trainer, num_epochs):\n    net.to(device)\n    loss = nn.CrossEntropyLoss(reduction='sum')\n    net.train()\n    train_accuracy, train_losses, test_accuracy =[], [], []\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n\n        for i, (X, y) in enumerate(train_iter):\n            X, y = X.to(device), y.to(device)\n            trainer.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            trainer.step()\n            train_l_sum += l.item()\n            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n            n += y.shape[0]\n\n            if i % 10 == 0:\n              print(f\"Step {i}. time since epoch: {time.time() -  start:.3f}. \"\n                    f\"Train acc: {train_acc_sum / n:.3f}. Train Loss: {train_l_sum / n:.3f}\")\n        test_acc = evaluate_accuracy(test_iter, net.to(device))\n        print('-' * 20)\n        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}'\n              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')\n        train_accuracy.append(train_acc_sum / n)\n        train_losses.append(train_l_sum / n)\n        test_accuracy.append(test_acc)\n    return train_accuracy, train_losses, test_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:37:59.401919Z","iopub.execute_input":"2023-12-14T19:37:59.402296Z","iopub.status.idle":"2023-12-14T19:37:59.412383Z","shell.execute_reply.started":"2023-12-14T19:37:59.402264Z","shell.execute_reply":"2023-12-14T19:37:59.411516Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 256\n# Переводим картинки в 224х224 и в тензор\ntransoforms = tv.transforms.Compose([\n    tv.transforms.Grayscale(3),\n    tv.transforms.Resize((224, 224)),\n    tv.transforms.ToTensor()\n])\ntrain_dataset = tv.datasets.EMNIST('.', split='mnist', train=True, transform=transoforms, download=True)\ntest_dataset = tv.datasets.EMNIST('.', split='mnist', train=False, transform=transoforms, download=True)\ntrain_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\ntest_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:38:46.494313Z","iopub.execute_input":"2023-12-14T19:38:46.494786Z","iopub.status.idle":"2023-12-14T19:38:46.5824Z","shell.execute_reply.started":"2023-12-14T19:38:46.494752Z","shell.execute_reply":"2023-12-14T19:38:46.581552Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 2. Обучение моделей","metadata":{}},{"cell_type":"code","source":"net = tv.models.densenet161(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:38:54.293291Z","iopub.execute_input":"2023-12-14T19:38:54.294006Z","iopub.status.idle":"2023-12-14T19:38:58.03672Z","shell.execute_reply.started":"2023-12-14T19:38:54.293972Z","shell.execute_reply":"2023-12-14T19:38:58.035736Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n100%|██████████| 110M/110M [00:03<00:00, 38.2MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"net","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:39:00.319642Z","iopub.execute_input":"2023-12-14T19:39:00.320318Z","iopub.status.idle":"2023-12-14T19:39:00.334433Z","shell.execute_reply.started":"2023-12-14T19:39:00.320282Z","shell.execute_reply":"2023-12-14T19:39:00.333552Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DenseNet(\n  (features): Sequential(\n    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu0): ReLU(inplace=True)\n    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (denseblock1): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition1): _Transition(\n      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock2): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition2): _Transition(\n      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock3): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer25): _DenseLayer(\n        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer26): _DenseLayer(\n        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer27): _DenseLayer(\n        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer28): _DenseLayer(\n        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer29): _DenseLayer(\n        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer30): _DenseLayer(\n        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer31): _DenseLayer(\n        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer32): _DenseLayer(\n        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer33): _DenseLayer(\n        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer34): _DenseLayer(\n        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer35): _DenseLayer(\n        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer36): _DenseLayer(\n        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition3): _Transition(\n      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock4): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Убираем требование градиента:\nfor param in net.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:39:55.66994Z","iopub.execute_input":"2023-12-14T19:39:55.670631Z","iopub.status.idle":"2023-12-14T19:39:55.677537Z","shell.execute_reply.started":"2023-12-14T19:39:55.670592Z","shell.execute_reply":"2023-12-14T19:39:55.676562Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"net.classifier","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:40:14.924477Z","iopub.execute_input":"2023-12-14T19:40:14.925176Z","iopub.status.idle":"2023-12-14T19:40:14.930848Z","shell.execute_reply.started":"2023-12-14T19:40:14.925132Z","shell.execute_reply":"2023-12-14T19:40:14.929956Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Linear(in_features=2208, out_features=1000, bias=True)"},"metadata":{}}]},{"cell_type":"code","source":"net.classifier = nn.Linear(in_features=2208, out_features=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:40:52.377494Z","iopub.execute_input":"2023-12-14T19:40:52.377866Z","iopub.status.idle":"2023-12-14T19:40:52.383465Z","shell.execute_reply.started":"2023-12-14T19:40:52.377836Z","shell.execute_reply":"2023-12-14T19:40:52.382528Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(\"Params to learn:\")\nparams_to_update = []\nfor name, param in net.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:41:20.714869Z","iopub.execute_input":"2023-12-14T19:41:20.715752Z","iopub.status.idle":"2023-12-14T19:41:20.724081Z","shell.execute_reply.started":"2023-12-14T19:41:20.715716Z","shell.execute_reply":"2023-12-14T19:41:20.723185Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Params to learn:\n\t classifier.weight\n\t classifier.bias\n","output_type":"stream"}]},{"cell_type":"code","source":"lr, num_epochs = 0.001, 10\ntrainer = torch.optim.Adam(params_to_update, lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:41:39.416278Z","iopub.execute_input":"2023-12-14T19:41:39.416649Z","iopub.status.idle":"2023-12-14T19:41:39.421568Z","shell.execute_reply.started":"2023-12-14T19:41:39.416619Z","shell.execute_reply":"2023-12-14T19:41:39.420566Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_accuracy, train_losses, test_accuracy  = train(net, train_iter, test_iter, trainer, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T19:41:46.52901Z","iopub.execute_input":"2023-12-14T19:41:46.529752Z","iopub.status.idle":"2023-12-14T20:34:41.539847Z","shell.execute_reply.started":"2023-12-14T19:41:46.529714Z","shell.execute_reply":"2023-12-14T20:34:41.538836Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Step 0. time since epoch: 2.463. Train acc: 0.137. Train Loss: 2.319\nStep 10. time since epoch: 15.698. Train acc: 0.429. Train Loss: 1.937\nStep 20. time since epoch: 28.838. Train acc: 0.574. Train Loss: 1.665\nStep 30. time since epoch: 41.929. Train acc: 0.658. Train Loss: 1.455\nStep 40. time since epoch: 55.066. Train acc: 0.706. Train Loss: 1.301\nStep 50. time since epoch: 68.167. Train acc: 0.739. Train Loss: 1.181\nStep 60. time since epoch: 81.308. Train acc: 0.762. Train Loss: 1.088\nStep 70. time since epoch: 94.390. Train acc: 0.780. Train Loss: 1.013\nStep 80. time since epoch: 107.514. Train acc: 0.794. Train Loss: 0.951\nStep 90. time since epoch: 120.677. Train acc: 0.806. Train Loss: 0.896\nStep 100. time since epoch: 133.765. Train acc: 0.816. Train Loss: 0.850\nStep 110. time since epoch: 146.987. Train acc: 0.825. Train Loss: 0.811\nStep 120. time since epoch: 160.138. Train acc: 0.832. Train Loss: 0.777\nStep 130. time since epoch: 173.218. Train acc: 0.840. Train Loss: 0.744\nStep 140. time since epoch: 186.445. Train acc: 0.846. Train Loss: 0.717\nStep 150. time since epoch: 199.497. Train acc: 0.851. Train Loss: 0.692\nStep 160. time since epoch: 212.669. Train acc: 0.856. Train Loss: 0.669\nStep 170. time since epoch: 225.760. Train acc: 0.861. Train Loss: 0.649\nStep 180. time since epoch: 238.983. Train acc: 0.864. Train Loss: 0.631\nStep 190. time since epoch: 252.129. Train acc: 0.868. Train Loss: 0.613\nStep 200. time since epoch: 265.212. Train acc: 0.871. Train Loss: 0.597\nStep 210. time since epoch: 278.414. Train acc: 0.874. Train Loss: 0.582\nStep 220. time since epoch: 291.540. Train acc: 0.877. Train Loss: 0.568\nStep 230. time since epoch: 304.728. Train acc: 0.879. Train Loss: 0.556\n--------------------\nepoch 1, loss 0.5519, train acc 0.880, test acc 0.941, time 344.5 sec\nStep 0. time since epoch: 1.239. Train acc: 0.938. Train Loss: 0.288\nStep 10. time since epoch: 13.148. Train acc: 0.938. Train Loss: 0.256\nStep 20. time since epoch: 25.035. Train acc: 0.942. Train Loss: 0.253\nStep 30. time since epoch: 36.920. Train acc: 0.945. Train Loss: 0.245\nStep 40. time since epoch: 48.822. Train acc: 0.946. Train Loss: 0.243\nStep 50. time since epoch: 60.699. Train acc: 0.946. Train Loss: 0.239\nStep 60. time since epoch: 72.573. Train acc: 0.946. Train Loss: 0.237\nStep 70. time since epoch: 84.569. Train acc: 0.947. Train Loss: 0.235\nStep 80. time since epoch: 96.425. Train acc: 0.946. Train Loss: 0.234\nStep 90. time since epoch: 108.258. Train acc: 0.947. Train Loss: 0.231\nStep 100. time since epoch: 120.128. Train acc: 0.947. Train Loss: 0.228\nStep 110. time since epoch: 131.981. Train acc: 0.947. Train Loss: 0.227\nStep 120. time since epoch: 143.831. Train acc: 0.947. Train Loss: 0.225\nStep 130. time since epoch: 155.696. Train acc: 0.948. Train Loss: 0.223\nStep 140. time since epoch: 167.559. Train acc: 0.948. Train Loss: 0.221\nStep 150. time since epoch: 179.490. Train acc: 0.948. Train Loss: 0.219\nStep 160. time since epoch: 191.332. Train acc: 0.949. Train Loss: 0.217\nStep 170. time since epoch: 203.198. Train acc: 0.949. Train Loss: 0.216\nStep 180. time since epoch: 215.158. Train acc: 0.949. Train Loss: 0.215\nStep 190. time since epoch: 227.020. Train acc: 0.950. Train Loss: 0.213\nStep 200. time since epoch: 238.930. Train acc: 0.950. Train Loss: 0.211\nStep 210. time since epoch: 250.775. Train acc: 0.950. Train Loss: 0.210\nStep 220. time since epoch: 262.614. Train acc: 0.951. Train Loss: 0.209\nStep 230. time since epoch: 274.539. Train acc: 0.951. Train Loss: 0.208\n--------------------\nepoch 2, loss 0.2075, train acc 0.951, test acc 0.956, time 313.9 sec\nStep 0. time since epoch: 1.216. Train acc: 0.953. Train Loss: 0.207\nStep 10. time since epoch: 13.094. Train acc: 0.958. Train Loss: 0.170\nStep 20. time since epoch: 25.024. Train acc: 0.961. Train Loss: 0.170\nStep 30. time since epoch: 36.845. Train acc: 0.961. Train Loss: 0.166\nStep 40. time since epoch: 48.702. Train acc: 0.961. Train Loss: 0.167\nStep 50. time since epoch: 60.557. Train acc: 0.961. Train Loss: 0.165\nStep 60. time since epoch: 72.408. Train acc: 0.961. Train Loss: 0.165\nStep 70. time since epoch: 84.288. Train acc: 0.961. Train Loss: 0.165\nStep 80. time since epoch: 96.135. Train acc: 0.960. Train Loss: 0.165\nStep 90. time since epoch: 107.993. Train acc: 0.961. Train Loss: 0.163\nStep 100. time since epoch: 119.898. Train acc: 0.961. Train Loss: 0.162\nStep 110. time since epoch: 131.771. Train acc: 0.961. Train Loss: 0.162\nStep 120. time since epoch: 143.653. Train acc: 0.960. Train Loss: 0.162\nStep 130. time since epoch: 155.460. Train acc: 0.960. Train Loss: 0.161\nStep 140. time since epoch: 167.323. Train acc: 0.960. Train Loss: 0.161\nStep 150. time since epoch: 179.192. Train acc: 0.960. Train Loss: 0.160\nStep 160. time since epoch: 191.033. Train acc: 0.961. Train Loss: 0.158\nStep 170. time since epoch: 202.883. Train acc: 0.961. Train Loss: 0.159\nStep 180. time since epoch: 214.846. Train acc: 0.961. Train Loss: 0.158\nStep 190. time since epoch: 226.699. Train acc: 0.961. Train Loss: 0.157\nStep 200. time since epoch: 238.557. Train acc: 0.961. Train Loss: 0.157\nStep 210. time since epoch: 250.403. Train acc: 0.962. Train Loss: 0.156\nStep 220. time since epoch: 262.253. Train acc: 0.962. Train Loss: 0.156\nStep 230. time since epoch: 274.107. Train acc: 0.962. Train Loss: 0.155\n--------------------\nepoch 3, loss 0.1555, train acc 0.962, test acc 0.962, time 313.4 sec\nStep 0. time since epoch: 1.197. Train acc: 0.957. Train Loss: 0.169\nStep 10. time since epoch: 13.129. Train acc: 0.967. Train Loss: 0.135\nStep 20. time since epoch: 25.145. Train acc: 0.967. Train Loss: 0.135\nStep 30. time since epoch: 37.079. Train acc: 0.967. Train Loss: 0.133\nStep 40. time since epoch: 49.113. Train acc: 0.966. Train Loss: 0.135\nStep 50. time since epoch: 61.057. Train acc: 0.966. Train Loss: 0.134\nStep 60. time since epoch: 73.059. Train acc: 0.967. Train Loss: 0.133\nStep 70. time since epoch: 85.108. Train acc: 0.967. Train Loss: 0.134\nStep 80. time since epoch: 97.077. Train acc: 0.967. Train Loss: 0.134\nStep 90. time since epoch: 109.093. Train acc: 0.967. Train Loss: 0.133\nStep 100. time since epoch: 121.055. Train acc: 0.967. Train Loss: 0.132\nStep 110. time since epoch: 133.025. Train acc: 0.967. Train Loss: 0.133\nStep 120. time since epoch: 145.047. Train acc: 0.967. Train Loss: 0.133\nStep 130. time since epoch: 157.063. Train acc: 0.966. Train Loss: 0.133\nStep 140. time since epoch: 169.080. Train acc: 0.966. Train Loss: 0.133\nStep 150. time since epoch: 181.048. Train acc: 0.966. Train Loss: 0.132\nStep 160. time since epoch: 193.005. Train acc: 0.967. Train Loss: 0.131\nStep 170. time since epoch: 204.960. Train acc: 0.967. Train Loss: 0.132\nStep 180. time since epoch: 216.922. Train acc: 0.967. Train Loss: 0.131\nStep 190. time since epoch: 228.946. Train acc: 0.967. Train Loss: 0.131\nStep 200. time since epoch: 240.892. Train acc: 0.967. Train Loss: 0.130\nStep 210. time since epoch: 252.865. Train acc: 0.967. Train Loss: 0.130\nStep 220. time since epoch: 264.801. Train acc: 0.967. Train Loss: 0.130\nStep 230. time since epoch: 276.774. Train acc: 0.967. Train Loss: 0.130\n--------------------\nepoch 4, loss 0.1301, train acc 0.967, test acc 0.964, time 316.1 sec\nStep 0. time since epoch: 1.175. Train acc: 0.965. Train Loss: 0.145\nStep 10. time since epoch: 13.192. Train acc: 0.971. Train Loss: 0.115\nStep 20. time since epoch: 25.126. Train acc: 0.972. Train Loss: 0.115\nStep 30. time since epoch: 37.020. Train acc: 0.971. Train Loss: 0.114\nStep 40. time since epoch: 49.065. Train acc: 0.970. Train Loss: 0.116\nStep 50. time since epoch: 61.002. Train acc: 0.970. Train Loss: 0.115\nStep 60. time since epoch: 72.958. Train acc: 0.971. Train Loss: 0.115\nStep 70. time since epoch: 85.002. Train acc: 0.971. Train Loss: 0.116\nStep 80. time since epoch: 96.898. Train acc: 0.970. Train Loss: 0.116\nStep 90. time since epoch: 108.853. Train acc: 0.970. Train Loss: 0.115\nStep 100. time since epoch: 120.815. Train acc: 0.970. Train Loss: 0.115\nStep 110. time since epoch: 132.717. Train acc: 0.970. Train Loss: 0.115\nStep 120. time since epoch: 144.698. Train acc: 0.970. Train Loss: 0.116\nStep 130. time since epoch: 156.671. Train acc: 0.970. Train Loss: 0.116\nStep 140. time since epoch: 168.573. Train acc: 0.970. Train Loss: 0.115\nStep 150. time since epoch: 180.529. Train acc: 0.970. Train Loss: 0.115\nStep 160. time since epoch: 192.471. Train acc: 0.970. Train Loss: 0.114\nStep 170. time since epoch: 204.498. Train acc: 0.970. Train Loss: 0.115\nStep 180. time since epoch: 216.492. Train acc: 0.970. Train Loss: 0.115\nStep 190. time since epoch: 228.437. Train acc: 0.970. Train Loss: 0.114\nStep 200. time since epoch: 240.397. Train acc: 0.970. Train Loss: 0.114\nStep 210. time since epoch: 252.314. Train acc: 0.970. Train Loss: 0.114\nStep 220. time since epoch: 264.388. Train acc: 0.970. Train Loss: 0.114\nStep 230. time since epoch: 276.358. Train acc: 0.970. Train Loss: 0.114\n--------------------\nepoch 5, loss 0.1143, train acc 0.970, test acc 0.966, time 315.7 sec\nStep 0. time since epoch: 1.183. Train acc: 0.969. Train Loss: 0.128\nStep 10. time since epoch: 13.130. Train acc: 0.974. Train Loss: 0.101\nStep 20. time since epoch: 24.965. Train acc: 0.973. Train Loss: 0.102\nStep 30. time since epoch: 36.953. Train acc: 0.974. Train Loss: 0.101\nStep 40. time since epoch: 48.846. Train acc: 0.973. Train Loss: 0.103\nStep 50. time since epoch: 60.912. Train acc: 0.973. Train Loss: 0.103\nStep 60. time since epoch: 72.858. Train acc: 0.973. Train Loss: 0.102\nStep 70. time since epoch: 84.913. Train acc: 0.973. Train Loss: 0.103\nStep 80. time since epoch: 96.870. Train acc: 0.973. Train Loss: 0.104\nStep 90. time since epoch: 108.845. Train acc: 0.973. Train Loss: 0.103\nStep 100. time since epoch: 120.765. Train acc: 0.973. Train Loss: 0.103\nStep 110. time since epoch: 132.716. Train acc: 0.973. Train Loss: 0.103\nStep 120. time since epoch: 144.763. Train acc: 0.972. Train Loss: 0.104\nStep 130. time since epoch: 156.723. Train acc: 0.972. Train Loss: 0.104\nStep 140. time since epoch: 168.725. Train acc: 0.972. Train Loss: 0.104\nStep 150. time since epoch: 180.579. Train acc: 0.972. Train Loss: 0.104\nStep 160. time since epoch: 192.436. Train acc: 0.972. Train Loss: 0.103\nStep 170. time since epoch: 204.352. Train acc: 0.972. Train Loss: 0.104\nStep 180. time since epoch: 216.165. Train acc: 0.972. Train Loss: 0.103\nStep 190. time since epoch: 228.149. Train acc: 0.973. Train Loss: 0.103\nStep 200. time since epoch: 240.011. Train acc: 0.973. Train Loss: 0.103\nStep 210. time since epoch: 251.865. Train acc: 0.973. Train Loss: 0.103\nStep 220. time since epoch: 263.814. Train acc: 0.972. Train Loss: 0.103\nStep 230. time since epoch: 275.672. Train acc: 0.972. Train Loss: 0.103\n--------------------\nepoch 6, loss 0.1032, train acc 0.972, test acc 0.967, time 315.0 sec\nStep 0. time since epoch: 1.179. Train acc: 0.973. Train Loss: 0.116\nStep 10. time since epoch: 13.112. Train acc: 0.978. Train Loss: 0.092\nStep 20. time since epoch: 24.956. Train acc: 0.978. Train Loss: 0.092\nStep 30. time since epoch: 36.822. Train acc: 0.977. Train Loss: 0.092\nStep 40. time since epoch: 48.709. Train acc: 0.975. Train Loss: 0.094\nStep 50. time since epoch: 60.567. Train acc: 0.975. Train Loss: 0.094\nStep 60. time since epoch: 72.515. Train acc: 0.976. Train Loss: 0.093\nStep 70. time since epoch: 84.371. Train acc: 0.975. Train Loss: 0.094\nStep 80. time since epoch: 96.272. Train acc: 0.975. Train Loss: 0.094\nStep 90. time since epoch: 108.240. Train acc: 0.975. Train Loss: 0.094\nStep 100. time since epoch: 120.094. Train acc: 0.975. Train Loss: 0.094\nStep 110. time since epoch: 132.001. Train acc: 0.975. Train Loss: 0.094\nStep 120. time since epoch: 143.815. Train acc: 0.975. Train Loss: 0.095\nStep 130. time since epoch: 155.688. Train acc: 0.974. Train Loss: 0.095\nStep 140. time since epoch: 167.552. Train acc: 0.974. Train Loss: 0.095\nStep 150. time since epoch: 179.444. Train acc: 0.974. Train Loss: 0.095\nStep 160. time since epoch: 191.296. Train acc: 0.975. Train Loss: 0.094\nStep 170. time since epoch: 203.295. Train acc: 0.974. Train Loss: 0.095\nStep 180. time since epoch: 215.121. Train acc: 0.975. Train Loss: 0.095\nStep 190. time since epoch: 227.001. Train acc: 0.975. Train Loss: 0.094\nStep 200. time since epoch: 238.837. Train acc: 0.975. Train Loss: 0.095\nStep 210. time since epoch: 250.722. Train acc: 0.975. Train Loss: 0.094\nStep 220. time since epoch: 262.676. Train acc: 0.975. Train Loss: 0.095\nStep 230. time since epoch: 274.562. Train acc: 0.975. Train Loss: 0.095\n--------------------\nepoch 7, loss 0.0948, train acc 0.975, test acc 0.968, time 313.8 sec\nStep 0. time since epoch: 1.177. Train acc: 0.973. Train Loss: 0.106\nStep 10. time since epoch: 13.144. Train acc: 0.978. Train Loss: 0.084\nStep 20. time since epoch: 25.011. Train acc: 0.979. Train Loss: 0.085\nStep 30. time since epoch: 36.959. Train acc: 0.978. Train Loss: 0.085\nStep 40. time since epoch: 48.795. Train acc: 0.977. Train Loss: 0.087\nStep 50. time since epoch: 60.660. Train acc: 0.976. Train Loss: 0.087\nStep 60. time since epoch: 72.583. Train acc: 0.977. Train Loss: 0.086\nStep 70. time since epoch: 84.486. Train acc: 0.977. Train Loss: 0.087\nStep 80. time since epoch: 96.336. Train acc: 0.977. Train Loss: 0.087\nStep 90. time since epoch: 108.295. Train acc: 0.976. Train Loss: 0.087\nStep 100. time since epoch: 120.156. Train acc: 0.976. Train Loss: 0.087\nStep 110. time since epoch: 132.126. Train acc: 0.976. Train Loss: 0.087\nStep 120. time since epoch: 143.969. Train acc: 0.976. Train Loss: 0.088\nStep 130. time since epoch: 155.863. Train acc: 0.976. Train Loss: 0.088\nStep 140. time since epoch: 167.747. Train acc: 0.976. Train Loss: 0.088\nStep 150. time since epoch: 179.641. Train acc: 0.976. Train Loss: 0.088\nStep 160. time since epoch: 191.491. Train acc: 0.976. Train Loss: 0.087\nStep 170. time since epoch: 203.383. Train acc: 0.976. Train Loss: 0.088\nStep 180. time since epoch: 215.270. Train acc: 0.976. Train Loss: 0.088\nStep 190. time since epoch: 227.208. Train acc: 0.976. Train Loss: 0.088\nStep 200. time since epoch: 239.087. Train acc: 0.976. Train Loss: 0.088\nStep 210. time since epoch: 251.007. Train acc: 0.976. Train Loss: 0.088\nStep 220. time since epoch: 262.938. Train acc: 0.976. Train Loss: 0.088\nStep 230. time since epoch: 274.827. Train acc: 0.976. Train Loss: 0.088\n--------------------\nepoch 8, loss 0.0882, train acc 0.976, test acc 0.969, time 314.1 sec\nStep 0. time since epoch: 1.173. Train acc: 0.973. Train Loss: 0.098\nStep 10. time since epoch: 13.115. Train acc: 0.979. Train Loss: 0.078\nStep 20. time since epoch: 24.990. Train acc: 0.980. Train Loss: 0.079\nStep 30. time since epoch: 36.988. Train acc: 0.980. Train Loss: 0.079\nStep 40. time since epoch: 48.812. Train acc: 0.979. Train Loss: 0.081\nStep 50. time since epoch: 60.628. Train acc: 0.978. Train Loss: 0.081\nStep 60. time since epoch: 72.449. Train acc: 0.979. Train Loss: 0.080\nStep 70. time since epoch: 84.281. Train acc: 0.978. Train Loss: 0.081\nStep 80. time since epoch: 96.113. Train acc: 0.978. Train Loss: 0.081\nStep 90. time since epoch: 108.022. Train acc: 0.978. Train Loss: 0.081\nStep 100. time since epoch: 119.848. Train acc: 0.978. Train Loss: 0.081\nStep 110. time since epoch: 131.737. Train acc: 0.978. Train Loss: 0.081\nStep 120. time since epoch: 143.564. Train acc: 0.978. Train Loss: 0.082\nStep 130. time since epoch: 155.398. Train acc: 0.977. Train Loss: 0.082\nStep 140. time since epoch: 167.253. Train acc: 0.977. Train Loss: 0.082\nStep 150. time since epoch: 179.111. Train acc: 0.977. Train Loss: 0.082\nStep 160. time since epoch: 191.080. Train acc: 0.977. Train Loss: 0.082\nStep 170. time since epoch: 202.935. Train acc: 0.977. Train Loss: 0.083\nStep 180. time since epoch: 214.774. Train acc: 0.977. Train Loss: 0.082\nStep 190. time since epoch: 226.624. Train acc: 0.978. Train Loss: 0.082\nStep 200. time since epoch: 238.480. Train acc: 0.978. Train Loss: 0.082\nStep 210. time since epoch: 250.353. Train acc: 0.978. Train Loss: 0.082\nStep 220. time since epoch: 262.289. Train acc: 0.977. Train Loss: 0.083\nStep 230. time since epoch: 274.151. Train acc: 0.977. Train Loss: 0.083\n--------------------\nepoch 9, loss 0.0827, train acc 0.977, test acc 0.969, time 313.4 sec\nStep 0. time since epoch: 1.182. Train acc: 0.977. Train Loss: 0.091\nStep 10. time since epoch: 13.097. Train acc: 0.981. Train Loss: 0.073\nStep 20. time since epoch: 24.934. Train acc: 0.981. Train Loss: 0.074\nStep 30. time since epoch: 36.816. Train acc: 0.981. Train Loss: 0.074\nStep 40. time since epoch: 48.679. Train acc: 0.980. Train Loss: 0.076\nStep 50. time since epoch: 60.544. Train acc: 0.979. Train Loss: 0.076\nStep 60. time since epoch: 72.462. Train acc: 0.980. Train Loss: 0.075\nStep 70. time since epoch: 84.292. Train acc: 0.979. Train Loss: 0.076\nStep 80. time since epoch: 96.165. Train acc: 0.979. Train Loss: 0.076\nStep 90. time since epoch: 108.062. Train acc: 0.979. Train Loss: 0.076\nStep 100. time since epoch: 119.918. Train acc: 0.979. Train Loss: 0.076\nStep 110. time since epoch: 131.823. Train acc: 0.979. Train Loss: 0.077\nStep 120. time since epoch: 143.661. Train acc: 0.979. Train Loss: 0.077\nStep 130. time since epoch: 155.519. Train acc: 0.979. Train Loss: 0.078\nStep 140. time since epoch: 167.401. Train acc: 0.979. Train Loss: 0.077\nStep 150. time since epoch: 179.269. Train acc: 0.978. Train Loss: 0.078\nStep 160. time since epoch: 191.166. Train acc: 0.979. Train Loss: 0.077\nStep 170. time since epoch: 203.070. Train acc: 0.979. Train Loss: 0.078\nStep 180. time since epoch: 214.928. Train acc: 0.979. Train Loss: 0.078\nStep 190. time since epoch: 226.952. Train acc: 0.979. Train Loss: 0.078\nStep 200. time since epoch: 238.792. Train acc: 0.979. Train Loss: 0.078\nStep 210. time since epoch: 250.656. Train acc: 0.979. Train Loss: 0.078\nStep 220. time since epoch: 262.527. Train acc: 0.979. Train Loss: 0.078\nStep 230. time since epoch: 274.403. Train acc: 0.979. Train Loss: 0.078\n--------------------\nepoch 10, loss 0.0781, train acc 0.979, test acc 0.969, time 313.7 sec\n","output_type":"stream"}]},{"cell_type":"code","source":"df_results= pd.DataFrame(columns = ['model', 'train_accuracy', 'train_loss', 'test_accuracy','epoch'])\nfor i in range(10):\n  df_results.loc[len(df_results.index)] = ['dencenet161',  train_accuracy[i], train_losses[i], test_accuracy[i], i]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:34:50.398178Z","iopub.execute_input":"2023-12-14T20:34:50.399049Z","iopub.status.idle":"2023-12-14T20:34:50.417621Z","shell.execute_reply.started":"2023-12-14T20:34:50.399014Z","shell.execute_reply":"2023-12-14T20:34:50.416694Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_results","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:34:53.159218Z","iopub.execute_input":"2023-12-14T20:34:53.159845Z","iopub.status.idle":"2023-12-14T20:34:53.17524Z","shell.execute_reply.started":"2023-12-14T20:34:53.159812Z","shell.execute_reply":"2023-12-14T20:34:53.174369Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"         model  train_accuracy  train_loss  test_accuracy  epoch\n0  dencenet161        0.879967    0.551938         0.9412      0\n1  dencenet161        0.950650    0.207485         0.9563      1\n2  dencenet161        0.961600    0.155470         0.9616      2\n3  dencenet161        0.967067    0.130077         0.9641      3\n4  dencenet161        0.970150    0.114286         0.9659      4\n5  dencenet161        0.972467    0.103202         0.9672      5\n6  dencenet161        0.974567    0.094830         0.9682      6\n7  dencenet161        0.976017    0.088192         0.9685      7\n8  dencenet161        0.977367    0.082741         0.9692      8\n9  dencenet161        0.978733    0.078149         0.9694      9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_accuracy</th>\n      <th>train_loss</th>\n      <th>test_accuracy</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dencenet161</td>\n      <td>0.879967</td>\n      <td>0.551938</td>\n      <td>0.9412</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dencenet161</td>\n      <td>0.950650</td>\n      <td>0.207485</td>\n      <td>0.9563</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dencenet161</td>\n      <td>0.961600</td>\n      <td>0.155470</td>\n      <td>0.9616</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dencenet161</td>\n      <td>0.967067</td>\n      <td>0.130077</td>\n      <td>0.9641</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dencenet161</td>\n      <td>0.970150</td>\n      <td>0.114286</td>\n      <td>0.9659</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>dencenet161</td>\n      <td>0.972467</td>\n      <td>0.103202</td>\n      <td>0.9672</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dencenet161</td>\n      <td>0.974567</td>\n      <td>0.094830</td>\n      <td>0.9682</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>dencenet161</td>\n      <td>0.976017</td>\n      <td>0.088192</td>\n      <td>0.9685</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>dencenet161</td>\n      <td>0.977367</td>\n      <td>0.082741</td>\n      <td>0.9692</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>dencenet161</td>\n      <td>0.978733</td>\n      <td>0.078149</td>\n      <td>0.9694</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_results.to_csv('dencenet_161.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:34:59.398989Z","iopub.execute_input":"2023-12-14T20:34:59.399775Z","iopub.status.idle":"2023-12-14T20:34:59.408649Z","shell.execute_reply.started":"2023-12-14T20:34:59.399736Z","shell.execute_reply":"2023-12-14T20:34:59.407367Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n# model = tv.models.inception_v3(pretrained=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Убираем требование градиента:\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Params to learn:\")\nparams_to_update = []\nfor name, param in model.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr, num_epochs = 0.001, 1\ntrainer = torch.optim.Adam(model.parameters(), lr=lr)\ntrain_accuracy, train_losses, test_accuracy  = train(model, train_iter, test_iter, trainer, num_epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n  df_results.loc[len(df_results.index)] = ['inception_v3',  train_accuracy[i], train_losses[i], test_accuracy[i], i]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.4. DenseNet 161","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tv.models.densenet161(pretrained=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Убираем требование градиента:\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.classifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Params to learn:\")\nparams_to_update = []\nfor name, param in model.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = torch.optim.Adam(params_to_update, lr=0.001)\ntrain_accuracy, train_losses, test_accuracy  = train(model, train_iter, test_iter, trainer, num_epochs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n  df_results.loc[len(df_results.index)] = ['densenet161',  train_accuracy[i], train_losses[i], test_accuracy[i], i]","metadata":{},"execution_count":null,"outputs":[]}]}